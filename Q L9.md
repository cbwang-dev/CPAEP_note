# Question 32 

> How does Easics limit the required memory bandwidth to internal as well as external memories (at least 3 different concepts are used here). For each of them discuss what kind of layers/networks benefit from this, and where it brings disadvantages?

To reduce internal memory bandwidth and external memory, Easics utilize systolic array to reuse data, in systolic array, use weight stationary, input shift to neighboring DSP blocks, so input are kind of stationary, this can reduce internal bandwidth.

1.  *Batch processing*
	- process N image together using same weight together to *reduce the overhead of weight loading*. 
	- *weight stationarity*. 
	- Disadvantage is increase the latency in real time inference.
![[mixlayer.png]]
2.  *Mix layer execution*. 
	- we execute part of ConvA, then use result immediately to execute part of ConvB. 
	- This method works well for tensors that are large in x and y directions. But, weights for 2 convolutions must fit in internal memory, Otherwise extra memory bandwidth for loading weights nullifies the gain.
3.  Winograd, introduce two new parameter A0, A1, which are related to weights and can be calculated off-line. Using the new parameter to reduce multiplication compared with classic method.
4.  Double speed clocking, DSP blocks can run at higher speed than other logic, double clock DSP blocks, use pre-adder to select between 2 weights, one input can be used twice to multiply different weights.

# Question 33 

> What data reuse and data stationarity does the Easics design exploits, both within one systolic array, as well as across systolic arrays? How to determine the optimal size of a systolic array? (advantages and disadvantages of the different options)

Page 29-35

| mode                                         | reuse  | stationarity |
| -------------------------------------------- | ------ | ------------ |
| single systolic array with $N^2$ multipliers | weight | none         |
| mask parallelism                             | weight |              |

# Question 34

> How does Easics maximally exploits the internal structure of the DSP blocks (explain how following things are exploited: the accumulator chains, the adders before the multipliers, the wide bitwidth of the multipliers, as well as the DSP speed capabilities)?

FPGA have internal optimized DSP blocks. Architecture of such blocks slightly changes in different models and brands, but they can be used for multiplying two different inputs and then using a programmable ALU to sum the product with a third input (accumulation). Multiple blocks can be combined in a systolic structure like TPU.

To reduce overall number of operations itâ€™s possible to apply Winograd modification which allows to use the extra adder present at the input of DSP blocks. This technique can be applied only over different output pixels, as it is done in systolic arrays. Parallel output can be defined according to latency and output buffer size.

Another way to speed up execution is to exploit DSP higher frequency and computing, with same pixel input but two different weights, double the data in a single cycle.